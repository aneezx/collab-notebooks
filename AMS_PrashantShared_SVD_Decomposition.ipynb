{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dd75e95",
   "metadata": {},
   "source": [
    "# Detailed Mathematical Explanation of SVD\n",
    "\n",
    "- **Matrix Factorization:** SVD is a method of decomposing a matrix $A$ into three matrices $U$, $\\Sigma$, and $V^T$ such that:\n",
    "  $$  A = U \\Sigma V^T $$\n",
    "  \n",
    "  \n",
    "  where:\n",
    "  - $U$ is an $m \\times m$ orthogonal matrix whose columns are the left singular vectors of $A$.\n",
    "  - $\\Sigma$ is an $m \\times n$ diagonal matrix with non-negative real numbers on the diagonal, known as singular values.\n",
    "  - $V^T$ is the transpose of an $n \\times n$ orthogonal matrix whose columns are the right singular vectors of $A$.\n",
    "\n",
    "- **Orthogonality of $U$ and $V$:**\n",
    "  - The columns of $U$ and $V$ are orthonormal, meaning that $U^T U = I$ and $V^T V = I$, where $I$ denotes the identity matrix.\n",
    "\n",
    "\n",
    "- **Singular Values:**\n",
    "  - The diagonal entries of $\\Sigma$ are called the singular values of $A$ and are denoted by $\\sigma_1, \\sigma_2, \\dots, \\sigma_r$ (with $r \\leq \\min(m, n)$). These are ordered such that $\\sigma_1 \\geq \\sigma_2 \\geq \\dots \\geq \\sigma_r \\geq 0$.\n",
    "  - Singular values provide insights into the \"strength\" or \"importance\" of the corresponding singular vectors in the matrix structure.\n",
    "\n",
    "\n",
    "- **Geometric Interpretation:**\n",
    "  - The transformation $A$ can be seen as stretching the unit sphere into an ellipsoid in $R^n$, where the singular values are the lengths of the semi-axes of the ellipsoid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda3b143-709b-412d-aa19-706cdb051f42",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "- Understanding SVD involves recognizing how a matrix can be broken down into simpler, meaningful components. Each component $U$, $\\Sigma$, and $V^T$ has a distinct role in transforming data.\n",
    "- The singular values in $\\Sigma$ represent the magnitude of each axis of the transformation, showing the importance of each dimension in the dataset.\n",
    "- This decomposition is particularly powerful because it reveals not just how data is structured but also the inherent relationships within the data, making it invaluable for complex data analyses and applications like compression, noise reduction, and more.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b24f1e2",
   "metadata": {},
   "source": [
    "## Step-by-Step SVD Decomposition Using NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "831d0a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a12cdf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the matrix that you want to decompose.\n",
    "# A = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "A = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaca264",
   "metadata": {},
   "source": [
    "## Step-by-Step SVD Decomposition Using NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cb8112",
   "metadata": {},
   "source": [
    "1. **Import NumPy Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "90ded50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a464c5f3",
   "metadata": {},
   "source": [
    "2. **Create a Matrix**\n",
    "   Define the matrix that you want to decompose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0cb42ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "A = np.array([[1, 2, 3], [4, 5, 6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a0b93c",
   "metadata": {},
   "source": [
    "3. **Compute Transpose and Multiplication**\n",
    "   Compute $ A^T A $ and $AA^T$ which are needed to find the right and left singular vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "beaba3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATA = np.dot(A.T, A)\n",
    "AAT = np.dot(A, A.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05cabf5",
   "metadata": {},
   "source": [
    "4. **Eigenvalue Decomposition**\n",
    "   Perform eigenvalue decomposition on $ A^T A $ and $ AA^T $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b0834f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_vals, e_vecs = np.linalg.eig(ATA)\n",
    "u_vals, u_vecs = np.linalg.eig(AAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9c0a78",
   "metadata": {},
   "source": [
    "5. **Sort Eigenvalues and Eigenvectors**\n",
    "   The singular values are the square roots of the eigenvalues of $A^T A$. Sort them (and corresponding vectors) by magnitude in descending order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3171e7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prashant\\AppData\\Local\\Temp\\ipykernel_27568\\2894977744.py:5: RuntimeWarning: invalid value encountered in sqrt\n",
      "  singular_values = np.sqrt(e_vals)\n"
     ]
    }
   ],
   "source": [
    "sorted_indices = np.argsort(e_vals)[::-1]\n",
    "e_vals = e_vals[sorted_indices]\n",
    "e_vecs = e_vecs[:, sorted_indices]\n",
    "\n",
    "singular_values = np.sqrt(e_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8408e59",
   "metadata": {},
   "source": [
    "6. **Form Diagonal Matrix $\\Sigma$**\n",
    "   Create $\\Sigma$ from the sorted singular values.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aa4304f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigma = np.zeros(A.shape)\n",
    "np.fill_diagonal(Sigma, singular_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1ed77704-f230-49f1-bfac-72645ad78bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.508032  , 0.        , 0.        ],\n",
       "       [0.        , 0.77286964, 0.        ]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e355a897",
   "metadata": {},
   "source": [
    "7. **Compute $V$ and $ U $ Matrices**\n",
    "   Ensure the left singular vectors (U) are normalized.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8760f01d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.92236578, -0.3863177 ],\n",
       "        [ 0.3863177 , -0.92236578]]),\n",
       " array([[-0.42866713, -0.80596391,  0.40824829],\n",
       "        [-0.56630692, -0.11238241, -0.81649658],\n",
       "        [-0.7039467 ,  0.58119908,  0.40824829]]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U = u_vecs\n",
    "V = e_vecs\n",
    "U,  V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e68af4",
   "metadata": {},
   "source": [
    "8. **Reconstruct Original Matrix**\n",
    "   Verify the decomposition by reconstructing $ A $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4d35c35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_reconstructed = np.dot(U, np.dot(Sigma, V.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954f471c",
   "metadata": {},
   "source": [
    "# Using SciPy for SVD\n",
    "\n",
    "Using SciPy, the SVD process is much more straightforward and handles numerical stability better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a815768c",
   "metadata": {},
   "source": [
    "1. **Import SciPy Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "51de59b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import svd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e52cc1",
   "metadata": {},
   "source": [
    "2. **Perform SVD**\n",
    "   Directly apply the SVD function.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a2921cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "U, s, VT = svd(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2a5cbc",
   "metadata": {},
   "source": [
    "3. **Form Diagonal Matrix $\\Sigma$ from s**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6c662f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigma = np.diag(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6637ce79",
   "metadata": {},
   "source": [
    "4. **Reconstruct Original Matrix**\n",
    "   Use the U, Sigma, and VT matrices to reconstruct $ A $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fdf44b81",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (2,2) and (3,3) not aligned: 2 (dim 1) != 3 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m A_reconstructed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(U, np\u001b[38;5;241m.\u001b[39mdot(Sigma, VT))\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (2,2) and (3,3) not aligned: 2 (dim 1) != 3 (dim 0)"
     ]
    }
   ],
   "source": [
    "A_reconstructed = np.dot(U, np.dot(Sigma, VT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235faf82",
   "metadata": {},
   "source": [
    "The error you're encountering occurs because the dimensions of the matrices involved in the matrix multiplication are not aligned properly. This is a common issue when reconstructing matrices from their SVD components, particularly when the original matrix $ A $ is not square (i.e., $ m \\neq n $).\n",
    "\n",
    "In SVD, $ U $, $ \\Sigma $, and $ V^T $ have specific shapes:\n",
    "- $ U $ is $ m \\times m $,\n",
    "- $ \\Sigma $ (as returned by `svd` in its minimal form) is $ \\min(m, n) \\times \\min(m, n) $,\n",
    "- $ V^T $ is $ n \\times n $.\n",
    "\n",
    "For a non-square $ A $ of size $ m \\times n $:\n",
    "- If $ m > n $, $ \\Sigma $ will be smaller than $ U $ in one dimension and smaller than $ V^T $ in the other, meaning direct multiplication won't work because of mismatched dimensions.\n",
    "\n",
    "Here's how you can fix this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c86760f",
   "metadata": {},
   "source": [
    "### Correct Reconstruction for Non-Square Matrices Using NumPy\n",
    "\n",
    "If you have used `scipy.linalg.svd` and retained the minimal $ \\Sigma $ (which is typically a 1D array of singular values), you need to construct the full $ \\Sigma $ matrix properly to match the dimensions of $ U $ and $ V^T $.\n",
    "\n",
    "Hereâ€™s the revised approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ffc91937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import svd\n",
    "\n",
    "# Example non-square matrix\n",
    "# A = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "A = np.array([[1, 2, 3], [4, 5, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1df389f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform SVD\n",
    "U, s, VT = svd(A, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ee6b80e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct full Sigma matrix with correct dimensions\n",
    "Sigma = np.zeros((U.shape[1], VT.shape[0]))\n",
    "np.fill_diagonal(Sigma, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "36ddc03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]]\n"
     ]
    }
   ],
   "source": [
    "# Reconstruct original matrix\n",
    "A_reconstructed = np.dot(U, np.dot(Sigma, VT))\n",
    "\n",
    "print(A_reconstructed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148bb46f",
   "metadata": {},
   "source": [
    "### Key Adjustments:\n",
    "\n",
    "1. **`full_matrices=False` in `svd` function**: This ensures that $ U $ and $ V^T $ are returned in reduced form, i.e., $ U $ will be $ m \\times \\min(m, n) $ and $ V^T $ will be $ \\min(m, n) \\times n $.\n",
    "2. **Constructing $ \\Sigma $**: Instead of using `np.diag(s)`, which only works if $ m = n $, the code now initializes $ \\Sigma $ as a zero matrix of appropriate size and fills its diagonal with the singular values stored in `s`. This matches $ \\Sigma $'s dimensions correctly with those of $ U $ and $ V^T $ for matrix multiplication.\n",
    "\n",
    "This method should resolve the dimension mismatch and successfully reconstruct the original matrix $ A $ from its SVD components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c749e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e3e502e-6f33-4904-9232-ca8735a19b03",
   "metadata": {},
   "source": [
    "# Orthogonal Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6888b29-0586-41f3-91ff-2483918bfb47",
   "metadata": {},
   "source": [
    "### Definition of Orthogonal Matrices\n",
    "\n",
    "An **orthogonal matrix** is a square matrix $ Q $ whose columns and rows are orthogonal unit vectors (orthonormal vectors). In simpler terms, this means that when a matrix is orthogonal, multiplying it by its transpose results in the identity matrix. Mathematically, this is represented as:\n",
    "$$ Q^T Q = Q Q^T = I $$\n",
    "where $ Q^T $ is the transpose of $ Q $, and $ I $ is the identity matrix of appropriate size.\n",
    "\n",
    "### Important Properties of Orthogonal Matrices\n",
    "\n",
    "1. **Preservation of Length (Norm):**\n",
    "   - Orthogonal transformations (represented by orthogonal matrices) preserve the length (norm) of vectors. If $ \\mathbf{v} $ is any vector, then $ \\| Q\\mathbf{v} \\| = \\| \\mathbf{v} \\| $. This property is crucial in many applications, including those in computer graphics and numerical methods, where maintaining the original length of vectors during transformations is necessary.\n",
    "\n",
    "2. **Preservation of Angle:**\n",
    "   - Orthogonal matrices preserve the angles between vectors. If $ \\mathbf{u} $ and $ \\mathbf{v} $ are vectors, then the angle between $ Q\\mathbf{u} $ and $ Q\\mathbf{v} $ is the same as the angle between $ \\mathbf{u} $ and $ \\mathbf{v} $. This is particularly useful in preserving the geometric properties of figures during transformations.\n",
    "\n",
    "3. **Inverse is Equal to Transpose:**\n",
    "   - The inverse of an orthogonal matrix is equal to its transpose: $ Q^{-1} = Q^T $. This simplifies computations involving matrix inversions, as calculating the transpose is generally more straightforward and computationally cheaper than finding the inverse.\n",
    "\n",
    "4. **Determinant Values:**\n",
    "   - The determinant of an orthogonal matrix is always $ \\pm 1 $. This arises from the property that the product of the eigenvalues (which are all $ \\pm 1 $ for orthogonal matrices) equals the determinant. The sign $ +1 $ indicates a rotation while $ -1 $ indicates a reflection combined with a rotation.\n",
    "\n",
    "5. **Stability in Numerical Computations:**\n",
    "   - Orthogonal matrices are numerically stable in computations, which makes them valuable in complex numerical calculations where minimizing error propagation is critical. For example, in algorithms like QR factorization used in solving linear systems, eigenvalue computations, and more.\n",
    "\n",
    "6. **Eigenvalues on the Unit Circle:**\n",
    "   - The eigenvalues of an orthogonal matrix lie on the unit circle in the complex plane. This means their absolute values are 1, reflecting the preservation of vector norms.\n",
    "\n",
    "### Applications\n",
    "\n",
    "Orthogonal matrices are widely used across various fields such as physics, engineering, computer graphics, and statistics. They are pivotal in transformations that require maintaining the original structure of data, such as rotations in space, reflecting shapes, and changing bases in vector spaces without distorting the vector magnitudes or angles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dd4998-1f71-423f-8959-d92dc3a599e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a13b2a-0c3d-4fa2-b9e0-33a1063db6c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
