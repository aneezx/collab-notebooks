{"cells":[{"cell_type":"code","execution_count":null,"id":"a18e27bb-c603-409f-909e-a4ed3060b9e1","metadata":{"id":"a18e27bb-c603-409f-909e-a4ed3060b9e1"},"outputs":[],"source":["import numpy as np\n","from scipy.linalg import lu"]},{"cell_type":"code","execution_count":null,"id":"482fe395-f16d-4cde-bcc5-fdf83e717d3a","metadata":{"id":"482fe395-f16d-4cde-bcc5-fdf83e717d3a"},"outputs":[],"source":["A = np.array([[2, 1, 1],\n","              [1, 3, 2],\n","              [1, 0, 0]])"]},{"cell_type":"code","execution_count":null,"id":"c5215eb7-5850-400a-a5e7-c40d7210f55d","metadata":{"id":"c5215eb7-5850-400a-a5e7-c40d7210f55d"},"outputs":[],"source":["P, L, U = lu(A)"]},{"cell_type":"code","execution_count":null,"id":"13a0fee8-3b2f-422b-96ec-c592acf26378","metadata":{"id":"13a0fee8-3b2f-422b-96ec-c592acf26378","outputId":"4154e4ed-b474-4c6d-c7f0-bc1b193e0dd8"},"outputs":[{"name":"stdout","output_type":"stream","text":["P:\n"," [[1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]]\n","L:\n"," [[ 1.   0.   0. ]\n"," [ 0.5  1.   0. ]\n"," [ 0.5 -0.2  1. ]]\n","U:\n"," [[ 2.   1.   1. ]\n"," [ 0.   2.5  1.5]\n"," [ 0.   0.  -0.2]]\n"]}],"source":["print(\"P:\\n\", P)\n","print(\"L:\\n\", L)\n","print(\"U:\\n\", U)"]},{"cell_type":"markdown","id":"d618ab24-e0b4-4417-bb97-5b02bc942df3","metadata":{"id":"d618ab24-e0b4-4417-bb97-5b02bc942df3"},"source":["## Reconstruct A Using Matrix Multiplication"]},{"cell_type":"code","execution_count":null,"id":"0c73e10d-cd50-4c9c-b7b8-3e60768e1112","metadata":{"id":"0c73e10d-cd50-4c9c-b7b8-3e60768e1112"},"outputs":[],"source":["A_reconstructed = np.dot(P, np.dot(L, U))"]},{"cell_type":"code","execution_count":null,"id":"edaabe8e-b4db-4c0c-9d0b-5ca8126fdb5c","metadata":{"id":"edaabe8e-b4db-4c0c-9d0b-5ca8126fdb5c","outputId":"63511f06-64a2-46a1-d406-6d56335e8c60"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reconstructed A:\n"," [[ 2.00000000e+00  1.00000000e+00  1.00000000e+00]\n"," [ 1.00000000e+00  3.00000000e+00  2.00000000e+00]\n"," [ 1.00000000e+00  0.00000000e+00 -2.77555756e-17]]\n"]}],"source":["print(\"Reconstructed A:\\n\", A_reconstructed)"]},{"cell_type":"code","execution_count":null,"id":"8654cb37-3690-4563-84fd-b3cf698627e7","metadata":{"id":"8654cb37-3690-4563-84fd-b3cf698627e7"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"e578d2f2-b38f-48f1-af79-1202514a3847","metadata":{"id":"e578d2f2-b38f-48f1-af79-1202514a3847"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"aa8ea8d8-66a7-44e0-995b-b0f5b010d050","metadata":{"id":"aa8ea8d8-66a7-44e0-995b-b0f5b010d050"},"source":["# Spectral decomposition"]},{"cell_type":"markdown","id":"a60cce8c-24ce-4a23-b412-86b460d508db","metadata":{"id":"a60cce8c-24ce-4a23-b412-86b460d508db"},"source":["Spectral decomposition, also known as eigenvalue decomposition, is a fundamental concept in linear algebra, particularly relevant to symmetric (or Hermitian in the complex case) matrices.\n","\n","It plays a critical role in many areas of mathematics, physics, engineering, and data science, especially in tasks involving principal component analysis, quantum mechanics, and various signal processing techniques.\n","\n","### Definition and Overview\n","\n","Spectral decomposition involves decomposing a matrix into a set of eigenvectors and eigenvalues. For a given square matrix $ A $, if $ A $ is symmetric, the spectral decomposition expresses $ A $ as:\n","\n","$ A = Q \\Lambda Q^T $\n","\n","where:\n","- $ Q $ is a matrix whose columns are the eigenvectors of $ A $.\n","- $ \\Lambda $ is a diagonal matrix whose diagonal elements are the corresponding eigenvalues.\n","- $ Q^T $ is the transpose of $ Q $.\n","\n","The key requirement here is that $ A $ must be symmetric, meaning $ A = A^T $. This condition guarantees that $ A $ has real eigenvalues and its eigenvectors are orthogonal.\n","\n","### Properties of Spectral Decomposition\n","\n","1. **Orthogonality of Eigenvectors**: The matrix $ Q $ is an orthogonal matrix. This means that the eigenvectors are not only linearly independent but also orthogonal to each other.\n","\n","2. **Diagonalizability**: A symmetric matrix $ A $ is always diagonalizable, meaning it can be expressed as the product of its eigenvectors and eigenvalues matrices as described above. This property stems from the fact that symmetric matrices do not have complex eigenvalues and their eigenvectors can be chosen orthogonally.\n","\n","3. **Reconstruction**: Given the eigenvectors and eigenvalues, the original matrix $ A $ can be reconstructed using the formula $ A = Q \\Lambda Q^T $.\n","\n","4. **Stability**: The spectral decomposition is numerically stable, making it a preferred method for numerical computations that involve eigenvalues and eigenvectors.\n","\n","### Applications in Data Science and Real World\n","\n","- **Principal Component Analysis (PCA)**: In data science, spectral decomposition is used to perform PCA, which is a technique to reduce the dimensionality of data while retaining those characteristics of the dataset that contribute most to its variance, by keeping lower-order principal components and ignoring higher-order ones.\n","  \n","- **Vibration Analysis**: In engineering, spectral decomposition is used to understand the vibration modes of a structure. Each eigenvalue can represent a natural frequency, and each eigenvector represents a mode shape of the structure under those frequencies.\n","\n","- **Quantum Mechanics**: In physics, particularly in quantum mechanics, spectral decomposition is used to solve the Schr√∂dinger equation. The eigenvalues represent the energy levels and the eigenvectors represent the state vectors of the system.\n","\n","- **Image Compression**: Spectral decomposition is also used in image compression techniques. By decomposing an image matrix into its spectral components, one can keep the most significant features (associated with larger eigenvalues) and achieve effective compression.\n","\n","Spectral decomposition thus serves as a powerful tool in both theoretical analyses and practical applications across various scientific and engineering disciplines.\n"]},{"cell_type":"code","execution_count":null,"id":"f1ef279e-bfb8-4518-8eb0-fcf1bbadd576","metadata":{"id":"f1ef279e-bfb8-4518-8eb0-fcf1bbadd576"},"outputs":[],"source":["import numpy as np\n","from numpy.linalg import eigh"]},{"cell_type":"code","execution_count":null,"id":"5991dba9-ad79-43a0-9f7b-ca3cd6e9a930","metadata":{"id":"5991dba9-ad79-43a0-9f7b-ca3cd6e9a930"},"outputs":[],"source":["# Step 2: Define a symmetric matrix\n","# We create a symmetric matrix A\n","A = np.array([[2, -1, 0],\n","              [-1, 2, -1],\n","              [0, -1, 2]])"]},{"cell_type":"code","execution_count":null,"id":"ef4d449f-4bba-43ae-a6ff-42360c0c4040","metadata":{"id":"ef4d449f-4bba-43ae-a6ff-42360c0c4040"},"outputs":[],"source":["# Step 3: Perform the spectral decomposition\n","# eigh returns the eigenvalues and eigenvectors of a Hermitian or symmetric matrix\n","eigenvalues, eigenvectors = eigh(A)"]},{"cell_type":"code","execution_count":null,"id":"61ad240d-9671-45af-8e5f-fe52586d6d94","metadata":{"id":"61ad240d-9671-45af-8e5f-fe52586d6d94"},"outputs":[],"source":["# Step 4: Verify the decomposition\n","# Reconstruct the original matrix\n","A_reconstructed = eigenvectors @ np.diag(eigenvalues) @ eigenvectors.T"]},{"cell_type":"code","execution_count":null,"id":"37337b77-ac8d-4578-b202-78495659d83d","metadata":{"id":"37337b77-ac8d-4578-b202-78495659d83d","outputId":"16d5507c-83d4-4fc3-e663-b77f22d751c4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original Matrix A:\n"," [[ 2 -1  0]\n"," [-1  2 -1]\n"," [ 0 -1  2]]\n","Eigenvalues:\n"," [0.58578644 2.         3.41421356]\n","Eigenvectors:\n"," [[ 5.00000000e-01 -7.07106781e-01 -5.00000000e-01]\n"," [ 7.07106781e-01  4.88509860e-17  7.07106781e-01]\n"," [ 5.00000000e-01  7.07106781e-01 -5.00000000e-01]]\n","Reconstructed Matrix A:\n"," [[ 2.00000000e+00 -1.00000000e+00 -1.40750406e-16]\n"," [-1.00000000e+00  2.00000000e+00 -1.00000000e+00]\n"," [-6.22457832e-17 -1.00000000e+00  2.00000000e+00]]\n"]}],"source":["# Print results\n","print(\"Original Matrix A:\\n\", A)\n","print(\"Eigenvalues:\\n\", eigenvalues)\n","print(\"Eigenvectors:\\n\", eigenvectors)\n","print(\"Reconstructed Matrix A:\\n\", A_reconstructed)"]},{"cell_type":"code","execution_count":null,"id":"8128282d-9867-4ea2-9693-5505246497e7","metadata":{"id":"8128282d-9867-4ea2-9693-5505246497e7"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"716afa82-5f58-4398-9d18-19216941ea9b","metadata":{"id":"716afa82-5f58-4398-9d18-19216941ea9b"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"2790a144-ca58-4349-aa89-9fb05148b21a","metadata":{"id":"2790a144-ca58-4349-aa89-9fb05148b21a"},"source":["# Comparison of Decomposition Methods"]},{"cell_type":"markdown","id":"dff91754-70b8-4155-9aed-722686c545f2","metadata":{"id":"dff91754-70b8-4155-9aed-722686c545f2"},"source":["Spectral decomposition, LU decomposition, and Singular Value Decomposition (SVD) are all matrix decomposition techniques used in linear algebra, but they differ in their methods, requirements, and applications. Understanding these differences can help clarify when to use each type of decomposition.\n","\n","### Spectral Decomposition (Eigenvalue Decomposition)\n","- **Applicability**: Spectral decomposition is specifically applicable to square, symmetric matrices (or Hermitian in the complex case). It cannot be used for non-square or non-symmetric matrices.\n","- **Decomposition**: It decomposes a matrix \\( A \\) into \\( Q \\Lambda Q^T \\), where \\( Q \\) is an orthogonal matrix whose columns are the eigenvectors of \\( A \\), and \\( \\Lambda \\) is a diagonal matrix containing the eigenvalues of \\( A \\).\n","- **Properties**: The matrix \\( A \\) must be symmetric, ensuring that all eigenvalues are real and the eigenvectors are orthogonal.\n","- **Use Cases**: Often used in scenarios involving optimization, quadratic forms, differential equations, and PCA where the matrix symmetry is assured.\n","\n","### LU Decomposition\n","- **Applicability**: LU decomposition can be applied to any square matrix, and extended forms like LDU or PLU can handle non-square matrices.\n","- **Decomposition**: It factorizes a matrix \\( A \\) into \\( P, L, \\) and \\( U \\) where \\( P \\) is a permutation matrix, \\( L \\) is a lower triangular matrix with unit diagonal elements, and \\( U \\) is an upper triangular matrix.\n","- **Properties**: It does not require the matrix \\( A \\) to be symmetric and is a fundamental method used for solving linear equations and matrix inversion.\n","- **Use Cases**: Commonly used in numerical solutions of systems of linear equations, where direct methods are applicable.\n","\n","### Singular Value Decomposition (SVD)\n","- **Applicability**: SVD can be applied to any \\( m \\times n \\) matrix, regardless of its properties of symmetry or square shape.\n","- **Decomposition**: It decomposes a matrix \\( A \\) into \\( U, \\Sigma, \\) and \\( V^T \\), where \\( U \\) and \\( V \\) are orthogonal matrices, and \\( \\Sigma \\) is a diagonal matrix (not necessarily square) containing the singular values.\n","- **Properties**: SVD is more general and robust, providing a decomposition even when \\( A \\) is not square or symmetric. The singular values in \\( \\Sigma \\) provide insights into the \"effect\" or \"impact\" of the corresponding singular vectors.\n","- **Use Cases**: Extensively used in signal processing, statistics, pattern recognition, and data reduction techniques like PCA. SVD is invaluable for problems involving pseudoinverse, least squares fitting, and condition number estimation.\n","\n","### Key Differences\n","- **Generality**: SVD is the most general form of decomposition, applicable to all matrices, while spectral decomposition is the most restrictive, limited only to square, symmetric matrices. LU sits in between, applicable to square matrices and extendable to non-square matrices.\n","- **Orthogonality**: Both SVD and spectral decomposition involve orthogonal matrices (in eigenvector and singular vector matrices), which preserve angles and lengths, unlike LU decomposition, which is merely a triangular decomposition without orthogonality constraints.\n","- **Mathematical Properties**: Spectral decomposition and SVD provide valuable insights into the geometric and statistical properties of the matrix (via eigenvalues and singular values), which are not directly obtainable from LU decomposition.\n","\n","Each decomposition has its place depending on the matrix properties and the specific requirements of the application, such as the need for solving systems of equations (LU), understanding intrinsic dimensional properties of data (SVD), or simplifying matrix operations in symmetric matrices (spectral decomposition)."]},{"cell_type":"code","execution_count":null,"id":"3f3eef98-2834-4fc3-84e3-558ed8a3816d","metadata":{"id":"3f3eef98-2834-4fc3-84e3-558ed8a3816d"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[{"file_id":"1U40kyOTenn-aqLggrp7GcNZ7qTT31oZQ","timestamp":1715050842521}]}},"nbformat":4,"nbformat_minor":5}